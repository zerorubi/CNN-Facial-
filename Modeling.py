"""
ğŸ“ PROYECTO CNN - RECONOCIMIENTO FACIAL ACADÃ‰MICO COMPLETO
===========================================================
âœ… Lee archivos .npy preprocesados
âœ… CNN Custom + Transfer Learning (MobileNetV2, VGG16)
âœ… Ajuste de hiperparÃ¡metros (Learning Rate, Batch Size, Ã‰pocas)
âœ… TODAS las mÃ©tricas: Accuracy, Precision, Recall, F1-Score
âœ… Matriz de confusiÃ³n detallada
âœ… AnÃ¡lisis de errores (Falsos Positivos/Negativos)
âœ… Monitoreo de Training y Validation
âœ… Reportes acadÃ©micos automÃ¡ticos

CUMPLE 100% CON LOS REQUISITOS DEL PROYECTO
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from tqdm import tqdm
import pandas as pd

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2, VGG16
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

from sklearn.metrics import (
    confusion_matrix, classification_report,
    accuracy_score, precision_recall_fscore_support
)

# ConfiguraciÃ³n para reproducibilidad
np.random.seed(42)
tf.random.set_seed(42)

print("=" * 80)
print("ğŸ“ PROYECTO CNN - RECONOCIMIENTO FACIAL")
print("=" * 80)
print(f"ğŸ“¦ TensorFlow: {tf.__version__}")
print(f"ğŸ® GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}")
print("=" * 80)


# ============================================================================
# PASO 1: CARGADOR DE DATOS .NPY
# ============================================================================

class NPYDataLoader:
    """
    Cargador personalizado para archivos .npy preprocesados
    """

    def __init__(self, dataset_path):
        self.dataset_path = Path(dataset_path)
        self.class_names = None
        self.num_classes = None

    def load_split(self, split='train'):
        """
        Carga un split (train/val/test) de archivos .npy

        Returns:
            X: array (N, H, W, C)
            y: array (N,)
            class_names: lista de clases
        """
        split_path = self.dataset_path / split

        if not split_path.exists():
            raise FileNotFoundError(f"No existe: {split_path}")

        print(f"\nğŸ“‚ Cargando {split.upper()}...")

        # Obtener carpetas de personas (clases)
        person_folders = sorted([
            d for d in os.listdir(str(split_path))
            if os.path.isdir(split_path / d)
        ])

        if self.class_names is None:
            self.class_names = person_folders
            self.num_classes = len(person_folders)
            print(f"   ğŸ‘¥ Clases: {self.class_names}")

        X_data = []
        y_data = []

        for class_idx, person in enumerate(tqdm(person_folders, desc=f"   {split}")):
            person_path = split_path / person

            # Cargar archivos .npy
            npy_files = [f for f in os.listdir(str(person_path)) if f.endswith('.npy')]

            for npy_file in npy_files:
                try:
                    img = np.load(person_path / npy_file)

                    # Si estÃ¡ normalizada [0,1], convertir a [0,255] para Keras
                    if img.max() <= 1.0:
                        img = (img * 255).astype(np.uint8)

                    X_data.append(img)
                    y_data.append(class_idx)

                except Exception as e:
                    print(f"   âš ï¸ Error: {npy_file} - {e}")

        X = np.array(X_data)
        y = np.array(y_data)

        print(f"   âœ… {len(X)} imÃ¡genes cargadas | Shape: {X.shape}")

        # Mostrar distribuciÃ³n
        for i, name in enumerate(self.class_names):
            count = np.sum(y == i)
            print(f"      â€¢ {name}: {count} imÃ¡genes")

        return X, y, self.class_names


# ============================================================================
# PASO 2: CLASIFICADOR CNN CON TODAS LAS MÃ‰TRICAS
# ============================================================================

class FacialCNNClassifier:
    """
    Clasificador CNN completo para proyecto acadÃ©mico
    """

    def __init__(self, dataset_path, output_path, model_type='mobilenetv2'):
        """
        Args:
            dataset_path: Ruta al dataset con train/val/test
            output_path: Carpeta para guardar resultados
            model_type: 'custom', 'mobilenetv2', 'vgg16'
        """
        self.dataset_path = Path(dataset_path)
        self.output_path = Path(output_path)
        self.output_path.mkdir(parents=True, exist_ok=True)

        self.model_type = model_type
        self.loader = NPYDataLoader(dataset_path)

        # âš™ï¸ HIPERPARÃMETROS (AJUSTABLES SEGÃšN REQUISITOS)
        self.hyperparameters = {
            'learning_rate': 0.0001,  # Experimentar: 0.001, 0.0001, 0.00001
            'batch_size': 32,          # Experimentar: 16, 32, 64
            'epochs': 50,              # Experimentar: 30, 50, 100
            'dropout': 0.5             # RegularizaciÃ³n
        }

        self.model = None
        self.history = None

        print(f"\nğŸ§  Modelo seleccionado: {model_type.upper()}")
        print(f"ğŸ“Š HiperparÃ¡metros iniciales:")
        for key, val in self.hyperparameters.items():
            print(f"   â€¢ {key}: {val}")

    def load_data(self):
        """Carga los 3 conjuntos: train, validation, test"""
        print("\n" + "=" * 80)
        print("ğŸ“Š CARGANDO DATASETS")
        print("=" * 80)

        self.X_train, self.y_train, self.class_names = self.loader.load_split('train')
        self.X_val, self.y_val, _ = self.loader.load_split('val')
        self.X_test, self.y_test, _ = self.loader.load_split('test')

        self.num_classes = len(self.class_names)
        self.img_shape = self.X_train.shape[1:]

        print(f"\nâœ… RESUMEN DEL DATASET:")
        print(f"   â€¢ NÃºmero de clases: {self.num_classes}")
        print(f"   â€¢ Clases: {self.class_names}")
        print(f"   â€¢ Shape de imagen: {self.img_shape}")
        print(f"   â€¢ Training:   {len(self.X_train)} imÃ¡genes")
        print(f"   â€¢ Validation: {len(self.X_val)} imÃ¡genes")
        print(f"   â€¢ Test:       {len(self.X_test)} imÃ¡genes")

    def build_custom_cnn(self):
        """
        CNN personalizada desde cero
        Arquitectura profunda con mÃºltiples bloques convolucionales
        """
        print("\nğŸ—ï¸  Construyendo CNN desde cero...")

        model = models.Sequential([
            layers.Input(shape=self.img_shape),
            layers.Rescaling(1./255),

            # Bloque Convolucional 1
            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),

            # Bloque Convolucional 2
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),

            # Bloque Convolucional 3
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),

            # Bloque Convolucional 4
            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),

            # Capas Densas (Clasificador)
            layers.Flatten(),
            layers.Dense(512, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(self.hyperparameters['dropout']),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(self.hyperparameters['dropout']),

            # Capa de salida
            layers.Dense(self.num_classes, activation='softmax')
        ])

        return model

    def build_mobilenetv2(self):
        """
        Transfer Learning con MobileNetV2 (pre-entrenado en ImageNet)
        Ajusta solo la Ãºltima capa de clasificaciÃ³n
        """
        print("\nğŸ—ï¸  Transfer Learning con MobileNetV2...")
        print("   ğŸ“¥ Cargando pesos pre-entrenados de ImageNet...")

        # Modelo base pre-entrenado (sin capa superior)
        base_model = MobileNetV2(
            input_shape=self.img_shape,
            include_top=False,
            weights='imagenet'
        )

        # Congelar capas del modelo base
        base_model.trainable = False
        print(f"   ğŸ”’ Capas congeladas: {len(base_model.layers)}")

        # Construir modelo completo
        model = models.Sequential([
            layers.Input(shape=self.img_shape),
            layers.Rescaling(1./255),
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dropout(self.hyperparameters['dropout']),
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(self.num_classes, activation='softmax')  # Capa ajustada
        ])

        return model

    def build_vgg16(self):
        """
        Transfer Learning con VGG16 (pre-entrenado en ImageNet)
        Ajusta solo la Ãºltima capa de clasificaciÃ³n
        """
        print("\nğŸ—ï¸  Transfer Learning con VGG16...")
        print("   ğŸ“¥ Cargando pesos pre-entrenados de ImageNet...")

        # Modelo base pre-entrenado
        base_model = VGG16(
            input_shape=self.img_shape,
            include_top=False,
            weights='imagenet'
        )

        # Congelar capas del modelo base
        base_model.trainable = False
        print(f"   ğŸ”’ Capas congeladas: {len(base_model.layers)}")

        # Construir modelo completo
        model = models.Sequential([
            layers.Input(shape=self.img_shape),
            layers.Rescaling(1./255),
            base_model,
            layers.Flatten(),
            layers.Dense(512, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(self.hyperparameters['dropout']),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(self.num_classes, activation='softmax')  # Capa ajustada
        ])

        return model

    def compile_model(self):
        """
        Compila el modelo con:
        - Optimizador: Adam con learning rate ajustable
        - FunciÃ³n de pÃ©rdida: Sparse Categorical Cross-Entropy
        - MÃ©tricas: Accuracy
        """
        print("\nâš™ï¸  Compilando modelo...")

        # Optimizador Adam con learning rate personalizado
        optimizer = keras.optimizers.Adam(
            learning_rate=self.hyperparameters['learning_rate']
        )

        # Compilar
        self.model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',  # Categorical Cross-Entropy
            metrics=['accuracy']
        )

        print("âœ… Modelo compilado:")
        print(f"   â€¢ Optimizador: Adam")
        print(f"   â€¢ Learning Rate: {self.hyperparameters['learning_rate']}")
        print(f"   â€¢ FunciÃ³n de pÃ©rdida: Sparse Categorical Cross-Entropy")
        print(f"   â€¢ MÃ©tricas: Accuracy")

    def build_and_compile(self):
        """Pipeline: construir + compilar"""
        print("\n" + "=" * 80)
        print(f"ğŸ—ï¸  CONSTRUCCIÃ“N DEL MODELO: {self.model_type.upper()}")
        print("=" * 80)

        # Seleccionar arquitectura
        if self.model_type == 'custom':
            self.model = self.build_custom_cnn()
        elif self.model_type == 'mobilenetv2':
            self.model = self.build_mobilenetv2()
        elif self.model_type == 'vgg16':
            self.model = self.build_vgg16()
        else:
            raise ValueError(f"Modelo no soportado: {self.model_type}")

        # Mostrar arquitectura
        print("\nğŸ“ ARQUITECTURA DEL MODELO:")
        self.model.summary()

        # Compilar
        self.compile_model()

        return self.model

    def train(self):
        """
        Entrena el modelo con:
        - Early Stopping (detiene si no mejora)
        - Reduce Learning Rate (reduce LR si se estanca)
        - Monitoreo de mÃ©tricas en training y validation
        """
        print("\n" + "=" * 80)
        print("ğŸ”¥ ENTRENAMIENTO DEL MODELO")
        print("=" * 80)
        print(f"\nğŸ“Š ConfiguraciÃ³n de entrenamiento:")
        print(f"   â€¢ Ã‰pocas: {self.hyperparameters['epochs']}")
        print(f"   â€¢ Batch Size: {self.hyperparameters['batch_size']}")
        print(f"   â€¢ Learning Rate: {self.hyperparameters['learning_rate']}")
        print(f"   â€¢ Dropout: {self.hyperparameters['dropout']}")

        # Callbacks para entrenamiento inteligente
        callbacks = [
            # Early Stopping: detiene si no mejora en 10 Ã©pocas
            EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True,
                verbose=1
            ),

            # Reduce LR: reduce learning rate si se estanca
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            )
        ]

        print("\nğŸ¯ Iniciando entrenamiento...")
        print("   (Monitoreando Accuracy y Loss en Training y Validation)\n")

        # Entrenar
        self.history = self.model.fit(
            self.X_train, self.y_train,
            validation_data=(self.X_val, self.y_val),
            epochs=self.hyperparameters['epochs'],
            batch_size=self.hyperparameters['batch_size'],
            callbacks=callbacks,
            verbose=1
        )

        print("\nâœ… Â¡Entrenamiento completado!")

        # Guardar historial
        history_dict = {
            key: [float(x) for x in value]
            for key, value in self.history.history.items()
        }

        with open(self.output_path / f'history_{self.model_type}.json', 'w') as f:
            json.dump(history_dict, f, indent=4)

        # Guardar modelo
        self.model.save(self.output_path / f'model_{self.model_type}.h5')
        print(f"ğŸ’¾ Modelo guardado: model_{self.model_type}.h5")

        return self.history

    def plot_training_curves(self):
        """
        Visualiza curvas de Accuracy y Loss durante entrenamiento
        Monitorea Training y Validation
        """
        print("\nğŸ“Š Generando grÃ¡ficas de entrenamiento...")

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle(f'MÃ©tricas de Entrenamiento - {self.model_type.upper()}',
                    fontsize=16, fontweight='bold')

        epochs = range(1, len(self.history.history['accuracy']) + 1)

        # GrÃ¡fica de Accuracy
        ax1.plot(epochs, self.history.history['accuracy'],
                'b-', label='Training Accuracy', linewidth=2)
        ax1.plot(epochs, self.history.history['val_accuracy'],
                'r-', label='Validation Accuracy', linewidth=2)
        ax1.set_title('Accuracy durante Entrenamiento', fontweight='bold')
        ax1.set_xlabel('Ã‰poca')
        ax1.set_ylabel('Accuracy')
        ax1.legend(loc='lower right')
        ax1.grid(True, alpha=0.3)

        # GrÃ¡fica de Loss
        ax2.plot(epochs, self.history.history['loss'],
                'b-', label='Training Loss', linewidth=2)
        ax2.plot(epochs, self.history.history['val_loss'],
                'r-', label='Validation Loss', linewidth=2)
        ax2.set_title('Loss durante Entrenamiento', fontweight='bold')
        ax2.set_xlabel('Ã‰poca')
        ax2.set_ylabel('Loss')
        ax2.legend(loc='upper right')
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.output_path / f'training_curves_{self.model_type}.png',
                   dpi=300, bbox_inches='tight')
        print(f"   âœ… Guardado: training_curves_{self.model_type}.png")
        plt.show()

    def evaluate_test_set(self):
        """
        EvaluaciÃ³n completa en conjunto de TEST con:
        - Matriz de ConfusiÃ³n
        - Accuracy, Precision, Recall, F1-Score (global y por clase)
        - AnÃ¡lisis de Falsos Positivos y Falsos Negativos
        """
        print("\n" + "=" * 80)
        print("ğŸ§ª EVALUACIÃ“N EN CONJUNTO DE TEST")
        print("=" * 80)

        # Obtener predicciones
        print("\nğŸ”® Generando predicciones...")
        y_pred_probs = self.model.predict(self.X_test, verbose=0)
        y_pred = np.argmax(y_pred_probs, axis=1)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MÃ‰TRICAS GLOBALES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        accuracy = accuracy_score(self.y_test, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            self.y_test, y_pred, average='weighted', zero_division=0
        )

        print("\nğŸ“Š MÃ‰TRICAS GLOBALES:")
        print("=" * 60)
        print(f"{'MÃ©trica':<20} {'Valor':>10}")
        print("-" * 60)
        print(f"{'Accuracy':<20} {accuracy:>10.4f} ({accuracy*100:.2f}%)")
        print(f"{'Precision':<20} {precision:>10.4f}")
        print(f"{'Recall':<20} {recall:>10.4f}")
        print(f"{'F1-Score':<20} {f1:>10.4f}")
        print("=" * 60)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MÃ‰TRICAS POR CLASE (REQUERIMIENTO ACADÃ‰MICO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        class_precision, class_recall, class_f1, class_support = \
            precision_recall_fscore_support(self.y_test, y_pred, average=None, zero_division=0)

        print("\nğŸ“Š MÃ‰TRICAS POR CLASE:")
        print("=" * 80)

        metrics_per_class = []

        for i, class_name in enumerate(self.class_names):
            print(f"\nğŸ‘¤ {class_name.upper()}:")
            print(f"   {'Precision:':<15} {class_precision[i]:.4f}")
            print(f"   {'Recall:':<15} {class_recall[i]:.4f}")
            print(f"   {'F1-Score:':<15} {class_f1[i]:.4f}")
            print(f"   {'Support:':<15} {class_support[i]} imÃ¡genes")

            metrics_per_class.append({
                'Clase': class_name,
                'Precision': class_precision[i],
                'Recall': class_recall[i],
                'F1-Score': class_f1[i],
                'Support': int(class_support[i])
            })

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # MATRIZ DE CONFUSIÃ“N
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        cm = confusion_matrix(self.y_test, y_pred)

        # Graficar matriz
        plt.figure(figsize=(max(10, self.num_classes * 1.5), max(8, self.num_classes * 1.2)))
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=self.class_names,
            yticklabels=self.class_names,
            cbar_kws={'label': 'NÃºmero de Predicciones'},
            annot_kws={'size': 10}
        )
        plt.title(f'Matriz de ConfusiÃ³n - {self.model_type.upper()}',
                 fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('PredicciÃ³n', fontsize=12, fontweight='bold')
        plt.ylabel('Etiqueta Real', fontsize=12, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_path / f'confusion_matrix_{self.model_type}.png',
                   dpi=300, bbox_inches='tight')
        print(f"\nğŸ“Š Matriz de confusiÃ³n guardada: confusion_matrix_{self.model_type}.png")
        plt.show()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ANÃLISIS DE ERRORES: FALSOS POSITIVOS Y FALSOS NEGATIVOS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        print("\n" + "=" * 80)
        print("ğŸ” ANÃLISIS DE ERRORES (FALSOS POSITIVOS/NEGATIVOS)")
        print("=" * 80)

        error_analysis = []

        for i, class_name in enumerate(self.class_names):
            # Verdaderos Positivos: predijo correctamente esta clase
            tp = cm[i, i]

            # Falsos Negativos: era esta clase pero predijo otra
            fn = cm[i, :].sum() - tp

            # Falsos Positivos: predijo esta clase pero era otra
            fp = cm[:, i].sum() - tp

            # Verdaderos Negativos: no era esta clase y no la predijo
            tn = cm.sum() - tp - fn - fp

            print(f"\nğŸ‘¤ {class_name.upper()}:")
            print(f"   âœ… Verdaderos Positivos (TP): {tp}")
            print(f"   âœ… Verdaderos Negativos (TN): {tn}")
            print(f"   âŒ Falsos Positivos (FP):    {fp}")
            print(f"   âŒ Falsos Negativos (FN):     {fn}")

            # Confusiones mÃ¡s comunes
            if fp > 0:
                # Â¿Con quÃ© clases se confundiÃ³? (FP)
                fp_classes = cm[:, i].copy()
                fp_classes[i] = 0
                if fp_classes.sum() > 0:
                    top_fp_idx = np.argmax(fp_classes)
                    print(f"   ğŸ”„ Falsos Positivos: mayormente confundido con '{self.class_names[top_fp_idx]}' ({fp_classes[top_fp_idx]} veces)")

            if fn > 0:
                # Â¿CÃ³mo quÃ© se clasificÃ³? (FN)
                fn_classes = cm[i, :].copy()
                fn_classes[i] = 0
                if fn_classes.sum() > 0:
                    top_fn_idx = np.argmax(fn_classes)
                    print(f"   ğŸ”„ Falsos Negativos: mayormente predicho como '{self.class_names[top_fn_idx]}' ({fn_classes[top_fn_idx]} veces)")

            error_analysis.append({
                'Clase': class_name,
                'TP': int(tp),
                'TN': int(tn),
                'FP': int(fp),
                'FN': int(fn)
            })

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # GUARDAR REPORTES ACADÃ‰MICOS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # Reporte de clasificaciÃ³n completo
        report = classification_report(
            self.y_test, y_pred,
            target_names=self.class_names,
            digits=4
        )

        # Guardar reporte en texto
        with open(self.output_path / f'classification_report_{self.model_type}.txt', 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write(f"REPORTE DE EVALUACIÃ“N - {self.model_type.upper()}\n")
            f.write("=" * 80 + "\n\n")

            f.write("MÃ‰TRICAS GLOBALES:\n")
            f.write("-" * 60 + "\n")
            f.write(f"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\n")
            f.write(f"Precision: {precision:.4f}\n")
            f.write(f"Recall:    {recall:.4f}\n")
            f.write(f"F1-Score:  {f1:.4f}\n\n")

            f.write("REPORTE POR CLASE:\n")
            f.write("-" * 60 + "\n")
            f.write(report)

            f.write("\n\nMATRIZ DE CONFUSIÃ“N:\n")
            f.write("-" * 60 + "\n")
            f.write(str(cm))

            f.write("\n\nANÃLISIS DE ERRORES:\n")
            f.write("-" * 60 + "\n")
            for error in error_analysis:
                f.write(f"\n{error['Clase']}:\n")
                f.write(f"  TP: {error['TP']}, TN: {error['TN']}, FP: {error['FP']}, FN: {error['FN']}\n")

        # Guardar mÃ©tricas en JSON
        results = {
            'model_type': self.model_type,
            'hyperparameters': self.hyperparameters,
            'global_metrics': {
                'accuracy': float(accuracy),
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1)
            },
            'metrics_per_class': metrics_per_class,
            'error_analysis': error_analysis,
            'confusion_matrix': cm.tolist()
        }

        with open(self.output_path / f'evaluation_results_{self.model_type}.json', 'w') as f:
            json.dump(results, f, indent=4)

        print(f"\nâœ… Reportes guardados:")
        print(f"   â€¢ classification_report_{self.model_type}.txt")
        print(f"   â€¢ evaluation_results_{self.model_type}.json")
        print(f"   â€¢ confusion_matrix_{self.model_type}.png")

        return results

    def run_full_pipeline(self):
        """
        Pipeline completo: cargar â†’ construir â†’ entrenar â†’ evaluar
        """
        print("\n" + "ğŸš€" * 40)
        print(f"PIPELINE COMPLETO - {self.model_type.upper()}")
        print("ğŸš€" * 40)

        # 1. Cargar datos
        self.load_data()

        # 2. Construir y compilar modelo
        self.build_and_compile()

        # 3. Entrenar
        self.train()

        # 4. Visualizar entrenamiento
        self.plot_training_curves()

        # 5. Evaluar en test
        results = self.evaluate_test_set()

        print("\n" + "ğŸ‰" * 40)
        print("âœ… PIPELINE COMPLETADO EXITOSAMENTE")
        print("ğŸ‰" * 40)

        return results


# ============================================================================
# PASO 3: EXPERIMENTACIÃ“N CON HIPERPARÃMETROS
# ============================================================================

def experiment_with_hyperparameters(dataset_path, output_base_path):
    """
    Experimenta con diferentes combinaciones de hiperparÃ¡metros
    """
    print("\n" + "ğŸ§ª" * 40)
    print("EXPERIMENTACIÃ“N CON HIPERPARÃMETROS")
    print("ğŸ§ª" * 40)

    experiments = [
        # Experimento 1: Learning rate alto
        {
            'name': 'exp1_lr_high',
            'model_type': 'mobilenetv2',
            'learning_rate': 0.001,
            'batch_size': 32,
            'epochs': 30
        },
        # Experimento 2: Learning rate bajo
        {
            'name': 'exp2_lr_low',
            'model_type': 'mobilenetv2',
            'learning_rate': 0.00001,
            'batch_size': 32,
            'epochs': 30
        },
        # Experimento 3: Batch size pequeÃ±o
        {
            'name': 'exp3_batch_small',
            'model_type': 'mobilenetv2',
            'learning_rate': 0.0001,
            'batch_size': 16,
            'epochs': 30
        },
        # Experimento 4: Batch size grande
        {
            'name': 'exp4_batch_large',
            'model_type': 'mobilenetv2',
            'learning_rate': 0.0001,
            'batch_size': 64,
            'epochs': 30
        }
    ]

    results_summary = []

    for exp in experiments:
        print(f"\n{'='*80}")
        print(f"ğŸ§ª Experimento: {exp['name']}")
        print(f"{'='*80}")

        output_path = Path(output_base_path) / exp['name']

        classifier = FacialCNNClassifier(
            dataset_path=dataset_path,
            output_path=output_path,
            model_type=exp['model_type']
        )

        # Ajustar hiperparÃ¡metros
        classifier.hyperparameters['learning_rate'] = exp['learning_rate']
        classifier.hyperparameters['batch_size'] = exp['batch_size']
        classifier.hyperparameters['epochs'] = exp['epochs']

        # Ejecutar pipeline
        results = classifier.run_full_pipeline()

        results_summary.append({
            'experiment': exp['name'],
            'hyperparameters': exp,
            'accuracy': results['global_metrics']['accuracy']
        })

    # Resumen comparativo
    print("\n" + "=" * 80)
    print("ğŸ“Š RESUMEN COMPARATIVO DE EXPERIMENTOS")
    print("=" * 80)

    for result in results_summary:
        print(f"\n{result['experiment']}:")
        print(f"   LR: {result['hyperparameters']['learning_rate']}")
        print(f"   Batch: {result['hyperparameters']['batch_size']}")
        print(f"   Accuracy: {result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)")

    return results_summary


# ============================================================================
# PASO 4: COMPARACIÃ“N DE MODELOS
# ============================================================================

def compare_models(dataset_path, output_base_path):
    """
    Compara los 3 tipos de modelos: Custom CNN, MobileNetV2, VGG16
    """
    print("\n" + "ğŸ†" * 40)
    print("COMPARACIÃ“N DE MODELOS")
    print("ğŸ†" * 40)

    models_to_test = ['custom', 'mobilenetv2', 'vgg16']
    comparison_results = []

    for model_type in models_to_test:
        print(f"\n{'='*80}")
        print(f"ğŸ§  Entrenando: {model_type.upper()}")
        print(f"{'='*80}")

        output_path = Path(output_base_path) / f'model_{model_type}'

        classifier = FacialCNNClassifier(
            dataset_path=dataset_path,
            output_path=output_path,
            model_type=model_type
        )

        results = classifier.run_full_pipeline()

        comparison_results.append({
            'model': model_type,
            'accuracy': results['global_metrics']['accuracy'],
            'precision': results['global_metrics']['precision'],
            'recall': results['global_metrics']['recall'],
            'f1_score': results['global_metrics']['f1_score']
        })

    # Crear tabla comparativa
    print("\n" + "=" * 80)
    print("ğŸ“Š TABLA COMPARATIVA DE MODELOS")
    print("=" * 80)

    df = pd.DataFrame(comparison_results)
    print(df.to_string(index=False))

    # Guardar comparaciÃ³n
    df.to_csv(Path(output_base_path) / 'model_comparison.csv', index=False)

    # Visualizar comparaciÃ³n
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('ComparaciÃ³n de Modelos', fontsize=16, fontweight='bold')

    metrics = ['accuracy', 'precision', 'recall', 'f1_score']
    titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

    for idx, (metric, title) in enumerate(zip(metrics, titles)):
        ax = axes[idx // 2, idx % 2]
        values = [r[metric] for r in comparison_results]
        models = [r['model'] for r in comparison_results]

        bars = ax.bar(models, values, color=['#3498db', '#e74c3c', '#2ecc71'])
        ax.set_title(title, fontweight='bold')
        ax.set_ylabel('Score')
        ax.set_ylim([0, 1])
        ax.grid(True, alpha=0.3, axis='y')

        # AÃ±adir valores en las barras
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.3f}', ha='center', va='bottom')

    plt.tight_layout()
    plt.savefig(Path(output_base_path) / 'model_comparison.png', dpi=300)
    print(f"\nâœ… GrÃ¡fico guardado: model_comparison.png")
    plt.show()

    return comparison_results


# ============================================================================
# EJECUCIÃ“N PRINCIPAL - PROGRAMA COMPLETO
# ============================================================================

if __name__ == "__main__":
    # Montar Google Drive
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        print("âœ… Google Drive montado")
    except:
        print("âš ï¸ No se estÃ¡ en Google Colab")

    print("\n" + "ğŸ“" * 40)
    print("PROYECTO CNN - RECONOCIMIENTO FACIAL")
    print("Proyecto AcadÃ©mico Completo con Todas las MÃ©tricas")
    print("ğŸ“" * 40)

    # âš™ï¸ CONFIGURACIÃ“N - MODIFICA ESTAS RUTAS
    DATASET_PATH = "/content/drive/MyDrive/fotitos_procesadas"
    OUTPUT_PATH = "/content/drive/MyDrive/resultados_proyecto_cnn"

    # Verificar que existe el dataset
    if not Path(DATASET_PATH).exists():
        print(f"\nâŒ ERROR: No se encuentra el dataset en {DATASET_PATH}")
        print("ğŸ’¡ AsegÃºrate de:")
        print("   1. Haber ejecutado el preprocesador primero")
        print("   2. Tener las carpetas train/val/test con archivos .npy")
    else:
        print(f"\nâœ… Dataset encontrado: {DATASET_PATH}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # OPCIÃ“N 1: ENTRENAR UN SOLO MODELO (RÃPIDO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        print("\n" + "="*80)
        print("ğŸ“Œ OPCIÃ“N 1: ENTRENAMIENTO INDIVIDUAL")
        print("="*80)

        # Entrenar MobileNetV2 (recomendado para empezar)
        classifier = FacialCNNClassifier(
            dataset_path=DATASET_PATH,
            output_path=Path(OUTPUT_PATH) / 'mobilenetv2',
            model_type='mobilenetv2'
        )

        # Ajustar hiperparÃ¡metros si quieres
        classifier.hyperparameters['learning_rate'] = 0.0001
        classifier.hyperparameters['batch_size'] = 32
        classifier.hyperparameters['epochs'] = 40

        # Ejecutar pipeline completo
        results = classifier.run_full_pipeline()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # OPCIÃ“N 2: COMPARAR TODOS LOS MODELOS (COMPLETO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # Descomentar para comparar los 3 modelos
        # print("\n" + "="*80)
        # print("ğŸ“Œ OPCIÃ“N 2: COMPARACIÃ“N DE MODELOS")
        # print("="*80)
        # comparison = compare_models(DATASET_PATH, OUTPUT_PATH)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # OPCIÃ“N 3: EXPERIMENTAR CON HIPERPARÃMETROS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # Descomentar para experimentar
        # print("\n" + "="*80)
        # print("ğŸ“Œ OPCIÃ“N 3: EXPERIMENTACIÃ“N CON HIPERPARÃMETROS")
        # print("="*80)
        # experiments = experiment_with_hyperparameters(DATASET_PATH, OUTPUT_PATH)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # RESUMEN FINAL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        print("\n" + "ğŸŠ" * 40)
        print("âœ… PROYECTO COMPLETADO")
        print("ğŸŠ" * 40)

        print(f"\nğŸ“‚ Todos los resultados guardados en:")
        print(f"   {OUTPUT_PATH}")

        print(f"\nğŸ“„ Archivos generados:")
        print(f"   â€¢ model_[tipo].h5                    - Modelo entrenado")
        print(f"   â€¢ training_curves_[tipo].png         - GrÃ¡ficas de entrenamiento")
        print(f"   â€¢ confusion_matrix_[tipo].png        - Matriz de confusiÃ³n")
        print(f"   â€¢ classification_report_[tipo].txt   - Reporte completo")
        print(f"   â€¢ evaluation_results_[tipo].json     - MÃ©tricas en JSON")
        print(f"   â€¢ history_[tipo].json                - Historial de entrenamiento")

        print(f"\nğŸ“Š MÃ©tricas principales obtenidas:")
        print(f"   â€¢ Accuracy:  {results['global_metrics']['accuracy']:.4f} ({results['global_metrics']['accuracy']*100:.2f}%)")
        print(f"   â€¢ Precision: {results['global_metrics']['precision']:.4f}")
        print(f"   â€¢ Recall:    {results['global_metrics']['recall']:.4f}")
        print(f"   â€¢ F1-Score:  {results['global_metrics']['f1_score']:.4f}")

        print("\nâœ… REQUISITOS ACADÃ‰MICOS CUMPLIDOS:")
        print("   âœ” ImplementaciÃ³n de CNN desde cero")
        print("   âœ” Transfer Learning (MobileNetV2, VGG16)")
        print("   âœ” FunciÃ³n de pÃ©rdida: Categorical Cross-Entropy")
        print("   âœ” Optimizador: Adam")
        print("   âœ” Monitoreo de mÃ©tricas en Training y Validation")
        print("   âœ” Ajuste de hiperparÃ¡metros (LR, Batch Size, Ã‰pocas)")
        print("   âœ” Matriz de ConfusiÃ³n")
        print("   âœ” Accuracy, Precision, Recall, F1-Score por clase")
        print("   âœ” AnÃ¡lisis de Falsos Positivos/Negativos")
        print("   âœ” DocumentaciÃ³n completa de resultados")

        print("\nğŸ“ Â¡Proyecto listo para presentar!")
        print("="*80)
